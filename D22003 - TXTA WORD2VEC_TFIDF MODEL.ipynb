{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0157b09",
   "metadata": {},
   "source": [
    "### SUBMITTED BY : AKANSHA RAJ (D22003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa6b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84e855",
   "metadata": {},
   "source": [
    "### Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b8a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file into pandas dataframe\n",
    "tweets = pd.read_csv(r\"C:\\Users\\Akansha Raj\\Downloads\\tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b23d004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of the dataframe\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b62b8ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the reviews with Average rating zero since they make no sense\n",
    "tweets = tweets[tweets.Avg!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345d9a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of the dataframe\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01fd1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the indexes of the dataframe and dropping the original index\n",
    "tweets.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.Avg = tweets.Avg.apply(lambda x: -1 if x<0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d054d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Average rating(target) column into binary classes\n",
    "for i in range(len(tweets)):\n",
    "    if tweets.Avg[i] <0 :\n",
    "        tweets.Avg[i] = -1\n",
    "    else:\n",
    "        tweets.Avg[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7179ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 5,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b27146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                               Tweet  Avg\n",
       " 0  I have to say, Apple has by far the best custo...  1.0\n",
       " 1  iOS 7 is so fricking smooth & beautiful!! #Tha...  1.0\n",
       " 2                                      LOVE U @APPLE  1.0\n",
       " 3  Thank you @apple, loving my new iPhone 5S!!!!!...  1.0\n",
       " 4  .@apple has the best customer service. In and ...  1.0,\n",
       "                                                  Tweet  Avg\n",
       " 839                                       freak @apple -1.0\n",
       " 840  WHY CANT I freakING SEE PICTURES ON MY TL IM A... -1.0\n",
       " 841                 @APPLE YOU freakING COWS freak YOU -1.0\n",
       " 842  @apple I hate you why is my phone not working ... -1.0\n",
       " 843  @aGounalakis that's nasty! @apple is a nasty brat -1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first and last 5 rows of the data-frame to get an overall feel of the data\n",
    "tweets.head(), tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67da78b",
   "metadata": {},
   "source": [
    "### Test Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f56a43",
   "metadata": {},
   "source": [
    "#### 1. Converting the text into lower cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dabdf6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ios 7 is so fricking smooth & beautiful!! #thanxapple @apple'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert a string into lower case\n",
    "twt = tweets.Tweet[1]\n",
    "twt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4861f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing all the tweets\n",
    "for i in range(len(tweets.Tweet)):\n",
    "    tweets.Tweet[i] = tweets.Tweet[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88930e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have to say, apple has by far the best custo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios 7 is so fricking smooth &amp; beautiful!! #tha...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love u @apple</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you @apple, loving my new iphone 5s!!!!!...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.@apple has the best customer service. in and ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg\n",
       "0  i have to say, apple has by far the best custo...  1.0\n",
       "1  ios 7 is so fricking smooth & beautiful!! #tha...  1.0\n",
       "2                                      love u @apple  1.0\n",
       "3  thank you @apple, loving my new iphone 5s!!!!!...  1.0\n",
       "4  .@apple has the best customer service. in and ...  1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b209a",
   "metadata": {},
   "source": [
    "#### 2. Remove Punctuations/special symbols and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2cca9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iOS 7 is so fricking smooth  beautiful ThanxApple Apple'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuation from a single tweet\n",
    "import string\n",
    "p = string.punctuation\n",
    "remv_punc = str.maketrans(\"\", \"\", p)\n",
    "twt.translate(remv_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c9f4330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have to say apple has by far the best custom...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios 7 is so fricking smooth  beautiful thanxap...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love u apple</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you apple loving my new iphone 5s  apple...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple has the best customer service in and out...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg\n",
       "0  i have to say apple has by far the best custom...  1.0\n",
       "1  ios 7 is so fricking smooth  beautiful thanxap...  1.0\n",
       "2                                       love u apple  1.0\n",
       "3  thank you apple loving my new iphone 5s  apple...  1.0\n",
       "4  apple has the best customer service in and out...  1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuation from all the tweets\n",
    "for i in range(len(tweets.Tweet)):\n",
    "    tweets.Tweet[i] = tweets.Tweet[i].translate(remv_punc)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c82d7",
   "metadata": {},
   "source": [
    "#### 3. Remove stopwords (and the word \"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00fe93bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aswin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94f0527f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK stopword list\n",
    "stop_words = stopwords.words(\"english\")\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8be6a278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the word apple to the list of stopwords\n",
    "stop_words.append(\"apple\")\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21adb233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'apple']\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29522461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say far best customer care service ever received appstore'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words from a single tweet\n",
    "\" \".join([w for w in tweets.Tweet[0].split() if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e51ce938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say far best customer care service ever receiv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios 7 fricking smooth beautiful thanxapple</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love u</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank loving new iphone 5s iphone5s pictwitter...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best customer service new phone 10min</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg\n",
       "0  say far best customer care service ever receiv...  1.0\n",
       "1         ios 7 fricking smooth beautiful thanxapple  1.0\n",
       "2                                             love u  1.0\n",
       "3  thank loving new iphone 5s iphone5s pictwitter...  1.0\n",
       "4              best customer service new phone 10min  1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing stopwords from all the tweets\n",
    "for i in range(len(tweets.Tweet)):\n",
    "    tweets.Tweet[i] = \" \".join([w for w in tweets.Tweet[i].split() if w not in stop_words])\n",
    "    \n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4653680",
   "metadata": {},
   "source": [
    "#### 4. Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf34c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say far best customer care service ever receiv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ios 7 fricking smooth beautiful thanxapple</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love u</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank loving new iphone 5s iphone5s pictwitter...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best customer service new phone 10min</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg\n",
       "0  say far best customer care service ever receiv...  1.0\n",
       "1         ios 7 fricking smooth beautiful thanxapple  1.0\n",
       "2                                             love u  1.0\n",
       "3  thank loving new iphone 5s iphone5s pictwitter...  1.0\n",
       "4              best customer service new phone 10min  1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tweets.Tweet)):\n",
    "    tweets.Tweet[i] = tweets.Tweet[i].replace(\"  \", \" \").strip()\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3dadcc",
   "metadata": {},
   "source": [
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "619f65d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "006536e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(a):\n",
    "    return(embeddings[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3a8ffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "308afe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting each document into a vector\n",
    "dict_1 = {}\n",
    "index_list = []\n",
    "for tweet,index in zip(tweets.Tweet,tweets.index):\n",
    "    rev_list = []\n",
    "    for word in tweet.split():\n",
    "        if word in embeddings.index_to_key:\n",
    "            index_list.append(index)\n",
    "            rev_list.append(vec(word))\n",
    "    dict_1[tweet] = np.sum(np.array(rev_list),axis=0)\n",
    "index_set = set(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1704d358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(index_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f6fa780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>say far best customer care service ever received appstore</th>\n",
       "      <td>-0.493164</td>\n",
       "      <td>-0.095337</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>0.540649</td>\n",
       "      <td>-0.170532</td>\n",
       "      <td>0.215515</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>-0.081055</td>\n",
       "      <td>1.091064</td>\n",
       "      <td>0.981018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279327</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>-1.071533</td>\n",
       "      <td>0.579533</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>0.483276</td>\n",
       "      <td>-0.215881</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>-0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ios 7 fricking smooth beautiful thanxapple</th>\n",
       "      <td>0.261780</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.431274</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.576843</td>\n",
       "      <td>-0.428833</td>\n",
       "      <td>0.376465</td>\n",
       "      <td>0.780273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202026</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>-0.687988</td>\n",
       "      <td>-0.214279</td>\n",
       "      <td>-0.215454</td>\n",
       "      <td>0.129150</td>\n",
       "      <td>-0.666016</td>\n",
       "      <td>-0.610046</td>\n",
       "      <td>-0.109131</td>\n",
       "      <td>0.459717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love u</th>\n",
       "      <td>-0.150879</td>\n",
       "      <td>-0.105713</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>-0.448242</td>\n",
       "      <td>-0.060059</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>-0.544922</td>\n",
       "      <td>-0.199707</td>\n",
       "      <td>0.302246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>-0.358398</td>\n",
       "      <td>-0.585938</td>\n",
       "      <td>-0.205322</td>\n",
       "      <td>-0.469727</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>-0.369141</td>\n",
       "      <td>-0.176514</td>\n",
       "      <td>0.253418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank loving new iphone 5s iphone5s pictwittercomxmhjcu4pcb</th>\n",
       "      <td>-0.685974</td>\n",
       "      <td>-0.154663</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.654785</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.230469</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.525146</td>\n",
       "      <td>-0.131836</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>0.766357</td>\n",
       "      <td>-0.982422</td>\n",
       "      <td>-0.664551</td>\n",
       "      <td>-0.309082</td>\n",
       "      <td>-0.283630</td>\n",
       "      <td>-0.598259</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>-0.448792</td>\n",
       "      <td>0.520508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best customer service new phone 10min</th>\n",
       "      <td>-0.210693</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.090088</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>-0.029053</td>\n",
       "      <td>-0.178711</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>0.424316</td>\n",
       "      <td>0.662659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328705</td>\n",
       "      <td>0.305664</td>\n",
       "      <td>-0.824219</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>0.265381</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>-0.471680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freak u</th>\n",
       "      <td>-0.048828</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.169617</td>\n",
       "      <td>0.110596</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>-0.050781</td>\n",
       "      <td>-0.541016</td>\n",
       "      <td>-0.139648</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.381836</td>\n",
       "      <td>-0.319824</td>\n",
       "      <td>-0.239258</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>-0.510742</td>\n",
       "      <td>-0.338379</td>\n",
       "      <td>-0.149780</td>\n",
       "      <td>-0.075073</td>\n",
       "      <td>0.107422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant freaking see pictures tl im annoyed freak twitter</th>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.265518</td>\n",
       "      <td>1.291504</td>\n",
       "      <td>-1.499268</td>\n",
       "      <td>0.956970</td>\n",
       "      <td>0.374115</td>\n",
       "      <td>-1.322784</td>\n",
       "      <td>0.530029</td>\n",
       "      <td>0.329895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>1.047729</td>\n",
       "      <td>-0.649292</td>\n",
       "      <td>-0.248840</td>\n",
       "      <td>-1.650391</td>\n",
       "      <td>-1.156738</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>-0.505722</td>\n",
       "      <td>-0.418335</td>\n",
       "      <td>0.028564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freaking cows freak</th>\n",
       "      <td>0.586914</td>\n",
       "      <td>-0.016846</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.423340</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.166382</td>\n",
       "      <td>-0.296600</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114258</td>\n",
       "      <td>0.328918</td>\n",
       "      <td>-0.202637</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>-0.231445</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>-0.358887</td>\n",
       "      <td>0.240845</td>\n",
       "      <td>0.085541</td>\n",
       "      <td>-0.060547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate phone working im going freak</th>\n",
       "      <td>0.347351</td>\n",
       "      <td>0.309204</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.426514</td>\n",
       "      <td>-0.717896</td>\n",
       "      <td>0.939087</td>\n",
       "      <td>0.136658</td>\n",
       "      <td>-0.739258</td>\n",
       "      <td>0.257324</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>-0.669189</td>\n",
       "      <td>-0.155579</td>\n",
       "      <td>-0.644287</td>\n",
       "      <td>-0.572754</td>\n",
       "      <td>-0.270996</td>\n",
       "      <td>-0.055420</td>\n",
       "      <td>0.218994</td>\n",
       "      <td>-0.158936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agounalakis thats nasty nasty brat</th>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.182861</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>-0.792969</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>-0.126495</td>\n",
       "      <td>-0.231934</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0.676025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547852</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>-0.803223</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>-0.302734</td>\n",
       "      <td>-0.732422</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>-0.128662</td>\n",
       "      <td>-0.046753</td>\n",
       "      <td>0.413818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1    \\\n",
       "say far best customer care service ever receive... -0.493164 -0.095337   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.261780 -0.117188   \n",
       "love u                                             -0.150879 -0.105713   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.685974 -0.154663   \n",
       "best customer service new phone 10min              -0.210693  0.010620   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.048828  0.039551   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.735931  0.201782   \n",
       "freaking cows freak                                 0.586914 -0.016846   \n",
       "hate phone working im going freak                   0.347351  0.309204   \n",
       "agounalakis thats nasty nasty brat                  0.386719  0.052124   \n",
       "\n",
       "                                                         2         3    \\\n",
       "say far best customer care service ever receive...  0.296143  0.540649   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.264160 -0.001953   \n",
       "love u                                              0.189941  0.146729   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.053223  0.654785   \n",
       "best customer service new phone 10min               0.281250  0.090088   \n",
       "...                                                      ...       ...   \n",
       "freak u                                             0.169617  0.110596   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.265518  1.291504   \n",
       "freaking cows freak                                 0.001648  0.423340   \n",
       "hate phone working im going freak                   0.310913  0.426514   \n",
       "agounalakis thats nasty nasty brat                  0.182861  0.861328   \n",
       "\n",
       "                                                         4         5    \\\n",
       "say far best customer care service ever receive... -0.170532  0.215515   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.431274  0.064209   \n",
       "love u                                             -0.448242 -0.060059   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.353271 -0.230469   \n",
       "best customer service new phone 10min               0.067139 -0.029053   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.368652  0.201172   \n",
       "cant freaking see pictures tl im annoyed freak ... -1.499268  0.956970   \n",
       "freaking cows freak                                -0.325684  0.740234   \n",
       "hate phone working im going freak                  -0.717896  0.939087   \n",
       "agounalakis thats nasty nasty brat                 -0.792969  0.715820   \n",
       "\n",
       "                                                         6         7    \\\n",
       "say far best customer care service ever receive...  0.673096 -0.081055   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.576843 -0.428833   \n",
       "love u                                              0.079102 -0.544922   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.068115 -0.525146   \n",
       "best customer service new phone 10min              -0.178711  0.016846   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.050781 -0.541016   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.374115 -1.322784   \n",
       "freaking cows freak                                 0.166382 -0.296600   \n",
       "hate phone working im going freak                   0.136658 -0.739258   \n",
       "agounalakis thats nasty nasty brat                 -0.126495 -0.231934   \n",
       "\n",
       "                                                         8         9    ...  \\\n",
       "say far best customer care service ever receive...  1.091064  0.981018  ...   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.376465  0.780273  ...   \n",
       "love u                                             -0.199707  0.302246  ...   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.131836  0.474243  ...   \n",
       "best customer service new phone 10min               0.424316  0.662659  ...   \n",
       "...                                                      ...       ...  ...   \n",
       "freak u                                            -0.139648 -0.018066  ...   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.530029  0.329895  ...   \n",
       "freaking cows freak                                 0.048584 -0.116699  ...   \n",
       "hate phone working im going freak                   0.257324  0.149170  ...   \n",
       "agounalakis thats nasty nasty brat                  0.094727  0.676025  ...   \n",
       "\n",
       "                                                         290       291  \\\n",
       "say far best customer care service ever receive... -0.279327  0.084229   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.202026  0.261108   \n",
       "love u                                              0.082275  0.326172   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.090332  0.766357   \n",
       "best customer service new phone 10min               0.328705  0.305664   \n",
       "...                                                      ...       ...   \n",
       "freak u                                             0.467773  0.381836   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.783691  1.047729   \n",
       "freaking cows freak                                 0.114258  0.328918   \n",
       "hate phone working im going freak                  -0.155029  0.922363   \n",
       "agounalakis thats nasty nasty brat                  0.547852  0.055420   \n",
       "\n",
       "                                                         292       293  \\\n",
       "say far best customer care service ever receive... -1.071533  0.579533   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.687988 -0.214279   \n",
       "love u                                             -0.358398 -0.585938   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.982422 -0.664551   \n",
       "best customer service new phone 10min              -0.824219  0.041870   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.319824 -0.239258   \n",
       "cant freaking see pictures tl im annoyed freak ... -0.649292 -0.248840   \n",
       "freaking cows freak                                -0.202637  0.109863   \n",
       "hate phone working im going freak                  -0.669189 -0.155579   \n",
       "agounalakis thats nasty nasty brat                 -0.803223  0.238281   \n",
       "\n",
       "                                                         294       295  \\\n",
       "say far best customer care service ever receive...  0.664551  0.483276   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.215454  0.129150   \n",
       "love u                                             -0.205322 -0.469727   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.309082 -0.283630   \n",
       "best customer service new phone 10min               0.265381  0.335083   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.363281 -0.510742   \n",
       "cant freaking see pictures tl im annoyed freak ... -1.650391 -1.156738   \n",
       "freaking cows freak                                -0.231445 -0.142578   \n",
       "hate phone working im going freak                  -0.644287 -0.572754   \n",
       "agounalakis thats nasty nasty brat                 -0.302734 -0.732422   \n",
       "\n",
       "                                                         296       297  \\\n",
       "say far best customer care service ever receive... -0.215881 -0.071289   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.666016 -0.610046   \n",
       "love u                                             -0.130859 -0.369141   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.598259  0.078613   \n",
       "best customer service new phone 10min              -0.138672  0.325439   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.338379 -0.149780   \n",
       "cant freaking see pictures tl im annoyed freak ... -0.439453 -0.505722   \n",
       "freaking cows freak                                -0.358887  0.240845   \n",
       "hate phone working im going freak                  -0.270996 -0.055420   \n",
       "agounalakis thats nasty nasty brat                  0.116943 -0.128662   \n",
       "\n",
       "                                                         298       299  \n",
       "say far best customer care service ever receive...  0.313599 -0.570312  \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.109131  0.459717  \n",
       "love u                                             -0.176514  0.253418  \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.448792  0.520508  \n",
       "best customer service new phone 10min              -0.018555 -0.471680  \n",
       "...                                                      ...       ...  \n",
       "freak u                                            -0.075073  0.107422  \n",
       "cant freaking see pictures tl im annoyed freak ... -0.418335  0.028564  \n",
       "freaking cows freak                                 0.085541 -0.060547  \n",
       "hate phone working im going freak                   0.218994 -0.158936  \n",
       "agounalakis thats nasty nasty brat                 -0.046753  0.413818  \n",
       "\n",
       "[827 rows x 300 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_matrix = pd.DataFrame(dict_1).T\n",
    "document_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "523c7ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are duplicate reviews in my dataset\n",
    "tweets.Tweet.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bb38564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_matrix=document_matrix.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eb81199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_matrix['Avg']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "351be27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tweets.Tweet)):\n",
    "    for j in range(len(document_matrix)):\n",
    "        if document_matrix['index'][j]==tweets['Tweet'][i]:\n",
    "            document_matrix['Avg'][j]=tweets['Avg'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9edfce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_matrix.set_index('index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "54eb4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = document_matrix.Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "20eca75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>say far best customer care service ever received appstore</th>\n",
       "      <td>-0.493164</td>\n",
       "      <td>-0.095337</td>\n",
       "      <td>0.296143</td>\n",
       "      <td>0.540649</td>\n",
       "      <td>-0.170532</td>\n",
       "      <td>0.215515</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>-0.081055</td>\n",
       "      <td>1.091064</td>\n",
       "      <td>0.981018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.279327</td>\n",
       "      <td>0.084229</td>\n",
       "      <td>-1.071533</td>\n",
       "      <td>0.579533</td>\n",
       "      <td>0.664551</td>\n",
       "      <td>0.483276</td>\n",
       "      <td>-0.215881</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>-0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ios 7 fricking smooth beautiful thanxapple</th>\n",
       "      <td>0.261780</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>0.264160</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.431274</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.576843</td>\n",
       "      <td>-0.428833</td>\n",
       "      <td>0.376465</td>\n",
       "      <td>0.780273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202026</td>\n",
       "      <td>0.261108</td>\n",
       "      <td>-0.687988</td>\n",
       "      <td>-0.214279</td>\n",
       "      <td>-0.215454</td>\n",
       "      <td>0.129150</td>\n",
       "      <td>-0.666016</td>\n",
       "      <td>-0.610046</td>\n",
       "      <td>-0.109131</td>\n",
       "      <td>0.459717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love u</th>\n",
       "      <td>-0.150879</td>\n",
       "      <td>-0.105713</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>-0.448242</td>\n",
       "      <td>-0.060059</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>-0.544922</td>\n",
       "      <td>-0.199707</td>\n",
       "      <td>0.302246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082275</td>\n",
       "      <td>0.326172</td>\n",
       "      <td>-0.358398</td>\n",
       "      <td>-0.585938</td>\n",
       "      <td>-0.205322</td>\n",
       "      <td>-0.469727</td>\n",
       "      <td>-0.130859</td>\n",
       "      <td>-0.369141</td>\n",
       "      <td>-0.176514</td>\n",
       "      <td>0.253418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thank loving new iphone 5s iphone5s pictwittercomxmhjcu4pcb</th>\n",
       "      <td>-0.685974</td>\n",
       "      <td>-0.154663</td>\n",
       "      <td>0.053223</td>\n",
       "      <td>0.654785</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.230469</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>-0.525146</td>\n",
       "      <td>-0.131836</td>\n",
       "      <td>0.474243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090332</td>\n",
       "      <td>0.766357</td>\n",
       "      <td>-0.982422</td>\n",
       "      <td>-0.664551</td>\n",
       "      <td>-0.309082</td>\n",
       "      <td>-0.283630</td>\n",
       "      <td>-0.598259</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>-0.448792</td>\n",
       "      <td>0.520508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best customer service new phone 10min</th>\n",
       "      <td>-0.210693</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.090088</td>\n",
       "      <td>0.067139</td>\n",
       "      <td>-0.029053</td>\n",
       "      <td>-0.178711</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>0.424316</td>\n",
       "      <td>0.662659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328705</td>\n",
       "      <td>0.305664</td>\n",
       "      <td>-0.824219</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>0.265381</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>-0.018555</td>\n",
       "      <td>-0.471680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freak u</th>\n",
       "      <td>-0.048828</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.169617</td>\n",
       "      <td>0.110596</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>0.201172</td>\n",
       "      <td>-0.050781</td>\n",
       "      <td>-0.541016</td>\n",
       "      <td>-0.139648</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467773</td>\n",
       "      <td>0.381836</td>\n",
       "      <td>-0.319824</td>\n",
       "      <td>-0.239258</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>-0.510742</td>\n",
       "      <td>-0.338379</td>\n",
       "      <td>-0.149780</td>\n",
       "      <td>-0.075073</td>\n",
       "      <td>0.107422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant freaking see pictures tl im annoyed freak twitter</th>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.265518</td>\n",
       "      <td>1.291504</td>\n",
       "      <td>-1.499268</td>\n",
       "      <td>0.956970</td>\n",
       "      <td>0.374115</td>\n",
       "      <td>-1.322784</td>\n",
       "      <td>0.530029</td>\n",
       "      <td>0.329895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783691</td>\n",
       "      <td>1.047729</td>\n",
       "      <td>-0.649292</td>\n",
       "      <td>-0.248840</td>\n",
       "      <td>-1.650391</td>\n",
       "      <td>-1.156738</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>-0.505722</td>\n",
       "      <td>-0.418335</td>\n",
       "      <td>0.028564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freaking cows freak</th>\n",
       "      <td>0.586914</td>\n",
       "      <td>-0.016846</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.423340</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.166382</td>\n",
       "      <td>-0.296600</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>-0.116699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114258</td>\n",
       "      <td>0.328918</td>\n",
       "      <td>-0.202637</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>-0.231445</td>\n",
       "      <td>-0.142578</td>\n",
       "      <td>-0.358887</td>\n",
       "      <td>0.240845</td>\n",
       "      <td>0.085541</td>\n",
       "      <td>-0.060547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate phone working im going freak</th>\n",
       "      <td>0.347351</td>\n",
       "      <td>0.309204</td>\n",
       "      <td>0.310913</td>\n",
       "      <td>0.426514</td>\n",
       "      <td>-0.717896</td>\n",
       "      <td>0.939087</td>\n",
       "      <td>0.136658</td>\n",
       "      <td>-0.739258</td>\n",
       "      <td>0.257324</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>-0.669189</td>\n",
       "      <td>-0.155579</td>\n",
       "      <td>-0.644287</td>\n",
       "      <td>-0.572754</td>\n",
       "      <td>-0.270996</td>\n",
       "      <td>-0.055420</td>\n",
       "      <td>0.218994</td>\n",
       "      <td>-0.158936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agounalakis thats nasty nasty brat</th>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.052124</td>\n",
       "      <td>0.182861</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>-0.792969</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>-0.126495</td>\n",
       "      <td>-0.231934</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0.676025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547852</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>-0.803223</td>\n",
       "      <td>0.238281</td>\n",
       "      <td>-0.302734</td>\n",
       "      <td>-0.732422</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>-0.128662</td>\n",
       "      <td>-0.046753</td>\n",
       "      <td>0.413818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0         1    \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive... -0.493164 -0.095337   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.261780 -0.117188   \n",
       "love u                                             -0.150879 -0.105713   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.685974 -0.154663   \n",
       "best customer service new phone 10min              -0.210693  0.010620   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.048828  0.039551   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.735931  0.201782   \n",
       "freaking cows freak                                 0.586914 -0.016846   \n",
       "hate phone working im going freak                   0.347351  0.309204   \n",
       "agounalakis thats nasty nasty brat                  0.386719  0.052124   \n",
       "\n",
       "                                                         2         3    \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive...  0.296143  0.540649   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.264160 -0.001953   \n",
       "love u                                              0.189941  0.146729   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.053223  0.654785   \n",
       "best customer service new phone 10min               0.281250  0.090088   \n",
       "...                                                      ...       ...   \n",
       "freak u                                             0.169617  0.110596   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.265518  1.291504   \n",
       "freaking cows freak                                 0.001648  0.423340   \n",
       "hate phone working im going freak                   0.310913  0.426514   \n",
       "agounalakis thats nasty nasty brat                  0.182861  0.861328   \n",
       "\n",
       "                                                         4         5    \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive... -0.170532  0.215515   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.431274  0.064209   \n",
       "love u                                             -0.448242 -0.060059   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.353271 -0.230469   \n",
       "best customer service new phone 10min               0.067139 -0.029053   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.368652  0.201172   \n",
       "cant freaking see pictures tl im annoyed freak ... -1.499268  0.956970   \n",
       "freaking cows freak                                -0.325684  0.740234   \n",
       "hate phone working im going freak                  -0.717896  0.939087   \n",
       "agounalakis thats nasty nasty brat                 -0.792969  0.715820   \n",
       "\n",
       "                                                         6         7    \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive...  0.673096 -0.081055   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.576843 -0.428833   \n",
       "love u                                              0.079102 -0.544922   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.068115 -0.525146   \n",
       "best customer service new phone 10min              -0.178711  0.016846   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.050781 -0.541016   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.374115 -1.322784   \n",
       "freaking cows freak                                 0.166382 -0.296600   \n",
       "hate phone working im going freak                   0.136658 -0.739258   \n",
       "agounalakis thats nasty nasty brat                 -0.126495 -0.231934   \n",
       "\n",
       "                                                         8         9    ...  \\\n",
       "index                                                                   ...   \n",
       "say far best customer care service ever receive...  1.091064  0.981018  ...   \n",
       "ios 7 fricking smooth beautiful thanxapple          0.376465  0.780273  ...   \n",
       "love u                                             -0.199707  0.302246  ...   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.131836  0.474243  ...   \n",
       "best customer service new phone 10min               0.424316  0.662659  ...   \n",
       "...                                                      ...       ...  ...   \n",
       "freak u                                            -0.139648 -0.018066  ...   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.530029  0.329895  ...   \n",
       "freaking cows freak                                 0.048584 -0.116699  ...   \n",
       "hate phone working im going freak                   0.257324  0.149170  ...   \n",
       "agounalakis thats nasty nasty brat                  0.094727  0.676025  ...   \n",
       "\n",
       "                                                         290       291  \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive... -0.279327  0.084229   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.202026  0.261108   \n",
       "love u                                              0.082275  0.326172   \n",
       "thank loving new iphone 5s iphone5s pictwitterc...  0.090332  0.766357   \n",
       "best customer service new phone 10min               0.328705  0.305664   \n",
       "...                                                      ...       ...   \n",
       "freak u                                             0.467773  0.381836   \n",
       "cant freaking see pictures tl im annoyed freak ...  0.783691  1.047729   \n",
       "freaking cows freak                                 0.114258  0.328918   \n",
       "hate phone working im going freak                  -0.155029  0.922363   \n",
       "agounalakis thats nasty nasty brat                  0.547852  0.055420   \n",
       "\n",
       "                                                         292       293  \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive... -1.071533  0.579533   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.687988 -0.214279   \n",
       "love u                                             -0.358398 -0.585938   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.982422 -0.664551   \n",
       "best customer service new phone 10min              -0.824219  0.041870   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.319824 -0.239258   \n",
       "cant freaking see pictures tl im annoyed freak ... -0.649292 -0.248840   \n",
       "freaking cows freak                                -0.202637  0.109863   \n",
       "hate phone working im going freak                  -0.669189 -0.155579   \n",
       "agounalakis thats nasty nasty brat                 -0.803223  0.238281   \n",
       "\n",
       "                                                         294       295  \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive...  0.664551  0.483276   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.215454  0.129150   \n",
       "love u                                             -0.205322 -0.469727   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.309082 -0.283630   \n",
       "best customer service new phone 10min               0.265381  0.335083   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.363281 -0.510742   \n",
       "cant freaking see pictures tl im annoyed freak ... -1.650391 -1.156738   \n",
       "freaking cows freak                                -0.231445 -0.142578   \n",
       "hate phone working im going freak                  -0.644287 -0.572754   \n",
       "agounalakis thats nasty nasty brat                 -0.302734 -0.732422   \n",
       "\n",
       "                                                         296       297  \\\n",
       "index                                                                    \n",
       "say far best customer care service ever receive... -0.215881 -0.071289   \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.666016 -0.610046   \n",
       "love u                                             -0.130859 -0.369141   \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.598259  0.078613   \n",
       "best customer service new phone 10min              -0.138672  0.325439   \n",
       "...                                                      ...       ...   \n",
       "freak u                                            -0.338379 -0.149780   \n",
       "cant freaking see pictures tl im annoyed freak ... -0.439453 -0.505722   \n",
       "freaking cows freak                                -0.358887  0.240845   \n",
       "hate phone working im going freak                  -0.270996 -0.055420   \n",
       "agounalakis thats nasty nasty brat                  0.116943 -0.128662   \n",
       "\n",
       "                                                         298       299  \n",
       "index                                                                   \n",
       "say far best customer care service ever receive...  0.313599 -0.570312  \n",
       "ios 7 fricking smooth beautiful thanxapple         -0.109131  0.459717  \n",
       "love u                                             -0.176514  0.253418  \n",
       "thank loving new iphone 5s iphone5s pictwitterc... -0.448792  0.520508  \n",
       "best customer service new phone 10min              -0.018555 -0.471680  \n",
       "...                                                      ...       ...  \n",
       "freak u                                            -0.075073  0.107422  \n",
       "cant freaking see pictures tl im annoyed freak ... -0.418335  0.028564  \n",
       "freaking cows freak                                 0.085541 -0.060547  \n",
       "hate phone working im going freak                   0.218994 -0.158936  \n",
       "agounalakis thats nasty nasty brat                 -0.046753  0.413818  \n",
       "\n",
       "[827 rows x 300 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_matrix.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66c759c",
   "metadata": {},
   "source": [
    "#### Train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f46720ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train-validation-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(document_matrix.iloc[:,:-1], y, test_size = 0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b3f2ff",
   "metadata": {},
   "source": [
    "#### 1. Using  fully grown decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "64c3c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the fully-grown decision tree is: 0.7014925373134329\n",
      "The F1-score of the fully-grown decision tree is: 0.6\n",
      "The AUROC of the fully-grown decision tree is: 0.684593023255814\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the decision tree classifier model, fitting the model on training data and making predictions on validation data\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_valid = dt.predict(X_valid)\n",
    "fg_ac = accuracy_score(y_valid,y_pred_valid)\n",
    "fg_f1 = f1_score(y_valid,y_pred_valid)\n",
    "fg_auroc = roc_auc_score(y_valid,y_pred_valid)\n",
    "print('The accuracy of the fully-grown decision tree is:',fg_ac)\n",
    "print('The F1-score of the fully-grown decision tree is:',fg_f1)\n",
    "print('The AUROC of the fully-grown decision tree is:',fg_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbad1b",
   "metadata": {},
   "source": [
    "#### 2. Using pruned decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "32408467",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dt.cost_complexity_pruning_path(X_train,y_train)\n",
    "alphas = path['ccp_alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2c15787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the decision tree model for different values of tuning parameter and making predictions on validation data \n",
    "valid_f1_score = {}\n",
    "valid_auc = {}\n",
    "for i in alphas:\n",
    "    dt = DecisionTreeClassifier(ccp_alpha=i)\n",
    "    dt.fit(X_train,y_train)\n",
    "    y_pred_valid = dt.predict(X_valid)\n",
    "    valid_f1_score[i] = f1_score(y_valid,y_pred_valid)\n",
    "    valid_auc[i] = roc_auc_score(y_valid,y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "12c9f9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003250899802623938"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the optimal value of alpha(tuning parameter) for which the modified cost is minimal (using f1_score as the performance metric)\n",
    "optimal_alpha = max(valid_f1_score,key=valid_f1_score.get)\n",
    "optimal_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "da7a157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the pruned decision tree with optimal ccp is: 0.6268656716417911\n",
      "The F1-score of the pruned decision tree with optimal ccp is: 0.4897959183673469\n",
      "The AUROC of the pruned decision tree with optimal ccp is: 0.5988372093023256\n"
     ]
    }
   ],
   "source": [
    "# Instatiating a pruned decision tree classifier with the optimal value of alpha, fitting the model on training data and making predictions on the validation data\n",
    "dt = DecisionTreeClassifier(ccp_alpha=optimal_alpha)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_valid = dt.predict(X_valid)\n",
    "pr_ac = accuracy_score(y_valid,y_pred_valid)\n",
    "pr_f1 = f1_score(y_valid,y_pred_valid)\n",
    "pr_auroc = roc_auc_score(y_valid,y_pred_valid)\n",
    "print('The accuracy of the pruned decision tree with optimal ccp is:',pr_ac)\n",
    "print('The F1-score of the pruned decision tree with optimal ccp is:',pr_f1)\n",
    "print('The AUROC of the pruned decision tree with optimal ccp is:',pr_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118247f",
   "metadata": {},
   "source": [
    "#### 3.Using random forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "92e30e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest Classifier is: 0.7164179104477612\n",
      "The F1-score of the Random Forest Classifier is:: 0.3870967741935483\n",
      "The AUROC of the Random Forest Classifier is: 0.6133720930232558\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the random forest classifier model, fitting the model on training data and making predictions on validation data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_valid_pred_rf = rf.predict(X_valid)\n",
    "rf_ac = accuracy_score(y_valid,y_valid_pred_rf)\n",
    "rf_f1 = f1_score(y_valid,y_valid_pred_rf)\n",
    "rf_auroc = roc_auc_score(y_valid,y_valid_pred_rf)\n",
    "print('The accuracy of the Random Forest Classifier is:',rf_ac)\n",
    "print('The F1-score of the Random Forest Classifier is::',rf_f1)\n",
    "print('The AUROC of the Random Forest Classifier is:',rf_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc11db2",
   "metadata": {},
   "source": [
    "#### 4.Using bagged classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9b37e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest Classifier is: 0.7611940298507462\n",
      "The F1-score of the Random Forest Classifier is:: 0.5555555555555556\n",
      "The AUROC of the Random Forest Classifier is: 0.6850775193798451\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the bagged classifier model, fitting the model on training data and making predictions on validation data\n",
    "bcf = BaggingClassifier()\n",
    "bcf.fit(X_train,y_train)\n",
    "y_valid_pred_bcf = bcf.predict(X_valid)\n",
    "bcf_ac = accuracy_score(y_valid,y_valid_pred_bcf)\n",
    "bcf_f1 = f1_score(y_valid,y_valid_pred_bcf)\n",
    "bcf_auroc = roc_auc_score(y_valid,y_valid_pred_bcf)\n",
    "print('The accuracy of the Random Forest Classifier is:',bcf_ac)\n",
    "print('The F1-score of the Random Forest Classifier is::',bcf_f1)\n",
    "print('The AUROC of the Random Forest Classifier is:',bcf_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a11df",
   "metadata": {},
   "source": [
    "#### 5.Using adaboost classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc6ca1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the ADABoost model is: 0.6567164179104478\n",
      "The F1-score of the ADABoost model is: 0.4102564102564102\n",
      "The AUROC of the ADABoost model is: 0.5852713178294573\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the adaboost classifier model, fitting the model on training data and making predictions on validation data\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)\n",
    "y_valid_pred_abc = abc.predict(X_valid)\n",
    "abc_ac = accuracy_score(y_valid,y_valid_pred_abc)\n",
    "abc_f1 = f1_score(y_valid,y_valid_pred_abc)\n",
    "abc_auroc = roc_auc_score(y_valid,y_valid_pred_abc)\n",
    "print('The accuracy of the ADABoost model is:',abc_ac)\n",
    "print('The F1-score of the ADABoost model is:',abc_f1)\n",
    "print('The AUROC of the ADABoost model is:',abc_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba8d9f",
   "metadata": {},
   "source": [
    "#### 6. Comparing the performance of the various models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b5fbaeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Decision Tree</th>\n",
       "      <th>Pruned Decision Tree</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-1 score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Standard Decision Tree Pruned Decision Tree Bagging Classifier  \\\n",
       "Accuracy                     NaN                  NaN                NaN   \n",
       "F-1 score                    NaN                  NaN                NaN   \n",
       "AUROC                        NaN                  NaN                NaN   \n",
       "\n",
       "          Random Forest AdaBoost  \n",
       "Accuracy            NaN      NaN  \n",
       "F-1 score           NaN      NaN  \n",
       "AUROC               NaN      NaN  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.DataFrame(columns=['Standard Decision Tree','Pruned Decision Tree','Bagging Classifier','Random Forest','AdaBoost'], index = ['Accuracy','F-1 score','AUROC'])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dce119c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70149254, 0.6       , 0.68459302],\n",
       "       [0.62686567, 0.48979592, 0.59883721],\n",
       "       [0.76119403, 0.55555556, 0.68507752],\n",
       "       [0.71641791, 0.38709677, 0.61337209],\n",
       "       [0.65671642, 0.41025641, 0.58527132]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_list = np.array([[fg_ac,fg_f1,fg_auroc],[pr_ac,pr_f1,pr_auroc],[bcf_ac,bcf_f1,bcf_auroc],[rf_ac,rf_f1,rf_auroc],[abc_ac,abc_f1,abc_auroc]])\n",
    "performance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b950fb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Decision Tree</th>\n",
       "      <th>Pruned Decision Tree</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-1 score</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.684593</td>\n",
       "      <td>0.598837</td>\n",
       "      <td>0.685078</td>\n",
       "      <td>0.613372</td>\n",
       "      <td>0.585271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Standard Decision Tree  Pruned Decision Tree  Bagging Classifier  \\\n",
       "Accuracy                 0.701493              0.626866            0.761194   \n",
       "F-1 score                0.600000              0.489796            0.555556   \n",
       "AUROC                    0.684593              0.598837            0.685078   \n",
       "\n",
       "           Random Forest  AdaBoost  \n",
       "Accuracy        0.716418  0.656716  \n",
       "F-1 score       0.387097  0.410256  \n",
       "AUROC           0.613372  0.585271  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,j in zip(list(performance.columns),np.arange(0,5)):\n",
    "    performance[i] = performance_list[j]\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4113d2c",
   "metadata": {},
   "source": [
    "### TF-IDF METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd45cb6",
   "metadata": {},
   "source": [
    "#### 1. Get the Bag-Of-Words (BOW) Dataframe with TF-IDF vectorizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "238a9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(tweets.Tweet)\n",
    "\n",
    "names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "tfidf_vectors = tfidf_vectors.toarray()\n",
    "tfidf_vectors = pd.DataFrame(tfidf_vectors, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7d8f9af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>075</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1085</th>\n",
       "      <th>10min</th>\n",
       "      <th>110</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>13apple</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>yikes</th>\n",
       "      <th>yldthng</th>\n",
       "      <th>yo</th>\n",
       "      <th>yooo</th>\n",
       "      <th>youd</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>z10</th>\n",
       "      <th>zimmerman</th>\n",
       "      <th>zippos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844 rows × 2953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     075   10  100  1085     10min  110   12   13  13apple   16  ...  yikes  \\\n",
       "0    0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "1    0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "2    0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "3    0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "4    0.0  0.0  0.0   0.0  0.558987  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "..   ...  ...  ...   ...       ...  ...  ...  ...      ...  ...  ...    ...   \n",
       "839  0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "840  0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "841  0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "842  0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "843  0.0  0.0  0.0   0.0  0.000000  0.0  0.0  0.0      0.0  0.0  ...    0.0   \n",
       "\n",
       "     yldthng   yo  yooo  youd  youre  youve  z10  zimmerman  zippos  \n",
       "0        0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "1        0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "2        0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "3        0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "4        0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "..       ...  ...   ...   ...    ...    ...  ...        ...     ...  \n",
       "839      0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "840      0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "841      0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "842      0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "843      0.0  0.0   0.0   0.0    0.0    0.0  0.0        0.0     0.0  \n",
       "\n",
       "[844 rows x 2953 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6921e",
   "metadata": {},
   "source": [
    "#### 2. Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6a74057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844, 140)\n"
     ]
    }
   ],
   "source": [
    "#using count vectorizer to create a document-term matrix (to select the features)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(tweets.Tweet).toarray()\n",
    "\n",
    "# Documnet-Term Matrix\n",
    "DTM = pd.DataFrame(X, columns=cv.get_feature_names())\n",
    "\n",
    "# Remove terms that is contained in less than 0.5% of the documents\n",
    "for col in list(DTM):\n",
    "    prop = DTM[col].sum()/DTM.shape[0]\n",
    "    if prop*100 < 1:\n",
    "        DTM = DTM.drop([col], axis=1)\n",
    "\n",
    "print(DTM.shape)\n",
    "\n",
    "selected_variables = list(DTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2133f121",
   "metadata": {},
   "source": [
    "#### 3.Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "648d8b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5c</th>\n",
       "      <th>5s</th>\n",
       "      <th>already</th>\n",
       "      <th>amazon</th>\n",
       "      <th>android</th>\n",
       "      <th>anyone</th>\n",
       "      <th>app</th>\n",
       "      <th>apples</th>\n",
       "      <th>apps</th>\n",
       "      <th>back</th>\n",
       "      <th>...</th>\n",
       "      <th>well</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>wtf</th>\n",
       "      <th>yall</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.724737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.431516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5c       5s  already  amazon   android  anyone  app  apples  apps  back  \\\n",
       "694  0.0  0.00000      0.0     0.0  0.724737     0.0  0.0     0.0   0.0   0.0   \n",
       "782  0.0  0.00000      0.0     0.0  0.000000     0.0  0.0     0.0   0.0   0.0   \n",
       "220  0.0  0.00000      0.0     0.0  0.000000     0.0  0.0     0.0   0.0   0.0   \n",
       "486  0.0  0.17822      0.0     0.0  0.000000     0.0  0.0     0.0   0.0   0.0   \n",
       "44   0.0  0.00000      0.0     0.0  0.000000     0.0  0.0     0.0   0.0   0.0   \n",
       "\n",
       "     ...  well      wont  work  would  wow  wtf  yall  year  yet  youre  \n",
       "694  ...   0.0  0.000000   0.0    0.0  0.0  0.0   0.0   0.0  0.0    0.0  \n",
       "782  ...   0.0  0.431516   0.0    0.0  0.0  0.0   0.0   0.0  0.0    0.0  \n",
       "220  ...   0.0  0.000000   0.0    0.0  0.0  0.0   0.0   0.0  0.0    0.0  \n",
       "486  ...   0.0  0.000000   0.0    0.0  0.0  0.0   0.0   0.0  0.0    0.0  \n",
       "44   ...   0.0  0.000000   0.0    0.0  0.0  0.0   0.0   0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the target variable\n",
    "y = tweets.Avg <= -1\n",
    "tfidf_vectors = tfidf_vectors[selected_variables]\n",
    "\n",
    "#For test-train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_vectors, y, test_size = 0.2, stratify=y)\n",
    "\n",
    "# Train-Validation Split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25, stratify=y_train)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442724fe",
   "metadata": {},
   "source": [
    "#### i) Using  fully grown decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba6a8a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the fully-grown decision tree is: 0.6153846153846154\n",
      "The F1-score of the fully-grown decision tree is: 0.7161572052401747\n",
      "The AUROC of the fully-grown decision tree is: 0.5599574984820886\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the decision tree classifier model, fitting the model on training data and making predictions on validation data\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_valid = dt.predict(X_valid)\n",
    "fg_ac = accuracy_score(y_valid,y_pred_valid)\n",
    "fg_f1 = f1_score(y_valid,y_pred_valid)\n",
    "fg_auroc = roc_auc_score(y_valid,y_pred_valid)\n",
    "print('The accuracy of the fully-grown decision tree is:',fg_ac)\n",
    "print('The F1-score of the fully-grown decision tree is:',fg_f1)\n",
    "print('The AUROC of the fully-grown decision tree is:',fg_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4852d36a",
   "metadata": {},
   "source": [
    "#### ii) Using pruned decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cc014c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dt.cost_complexity_pruning_path(X_train,y_train)\n",
    "alphas = path['ccp_alphas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9366f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the decision tree model for different values of tuning parameter and making predictions on validation data \n",
    "valid_f1_score = {}\n",
    "valid_auc = {}\n",
    "for i in alphas:\n",
    "    dt = DecisionTreeClassifier(ccp_alpha=i)\n",
    "    dt.fit(X_train,y_train)\n",
    "    y_pred_valid = dt.predict(X_valid)\n",
    "    valid_f1_score[i] = f1_score(y_valid,y_pred_valid)\n",
    "    valid_auc[i] = roc_auc_score(y_valid,y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "85c945d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008484204384498345"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the optimal value of alpha(tuning parameter) for which the modified cost is minimal (using f1_score as the performance metric)\n",
    "optimal_alpha = max(valid_f1_score,key=valid_f1_score.get)\n",
    "optimal_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a25a4018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the pruned decision tree with optimal ccp is: 0.650887573964497\n",
      "The F1-score of the pruned decision tree with optimal ccp is: 0.7822878228782287\n",
      "The AUROC of the pruned decision tree with optimal ccp is: 0.5235276259866424\n"
     ]
    }
   ],
   "source": [
    "# Instatiating a pruned decision tree classifier with the optimal value of alpha, fitting the model on training data and making predictions on the validation data\n",
    "dt = DecisionTreeClassifier(ccp_alpha=optimal_alpha)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_valid = dt.predict(X_valid)\n",
    "pr_ac = accuracy_score(y_valid,y_pred_valid)\n",
    "pr_f1 = f1_score(y_valid,y_pred_valid)\n",
    "pr_auroc = roc_auc_score(y_valid,y_pred_valid)\n",
    "print('The accuracy of the pruned decision tree with optimal ccp is:',pr_ac)\n",
    "print('The F1-score of the pruned decision tree with optimal ccp is:',pr_f1)\n",
    "print('The AUROC of the pruned decision tree with optimal ccp is:',pr_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd3b21f",
   "metadata": {},
   "source": [
    "#### iii) Using random forest classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d729ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest Classifier is: 0.6449704142011834\n",
      "The F1-score of the Random Forest Classifier is:: 0.7169811320754716\n",
      "The AUROC of the Random Forest Classifier is: 0.6223436551305404\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the random forest classifier model, fitting the model on training data and making predictions on validation data\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_valid_pred_rf = rf.predict(X_valid)\n",
    "rf_ac = accuracy_score(y_valid,y_valid_pred_rf)\n",
    "rf_f1 = f1_score(y_valid,y_valid_pred_rf)\n",
    "rf_auroc = roc_auc_score(y_valid,y_valid_pred_rf)\n",
    "print('The accuracy of the Random Forest Classifier is:',rf_ac)\n",
    "print('The F1-score of the Random Forest Classifier is::',rf_f1)\n",
    "print('The AUROC of the Random Forest Classifier is:',rf_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e918e",
   "metadata": {},
   "source": [
    "#### iv) Using bagged classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ee27dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Random Forest Classifier is: 0.6153846153846154\n",
      "The F1-score of the Random Forest Classifier is:: 0.6829268292682927\n",
      "The AUROC of the Random Forest Classifier is: 0.602762598664238\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the bagged classifier model, fitting the model on training data and making predictions on validation data\n",
    "bcf = BaggingClassifier()\n",
    "bcf.fit(X_train,y_train)\n",
    "y_valid_pred_bcf = bcf.predict(X_valid)\n",
    "bcf_ac = accuracy_score(y_valid,y_valid_pred_bcf)\n",
    "bcf_f1 = f1_score(y_valid,y_valid_pred_bcf)\n",
    "bcf_auroc = roc_auc_score(y_valid,y_valid_pred_bcf)\n",
    "print('The accuracy of the Random Forest Classifier is:',bcf_ac)\n",
    "print('The F1-score of the Random Forest Classifier is::',bcf_f1)\n",
    "print('The AUROC of the Random Forest Classifier is:',bcf_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc447c65",
   "metadata": {},
   "source": [
    "#### vi) Using adaboost classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92582a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the ADABoost model is: 0.6627218934911243\n",
      "The F1-score of the ADABoost model is: 0.7710843373493975\n",
      "The AUROC of the ADABoost model is: 0.5755919854280509\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the adaboost classifier model, fitting the model on training data and making predictions on validation data\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)\n",
    "y_valid_pred_abc = abc.predict(X_valid)\n",
    "abc_ac = accuracy_score(y_valid,y_valid_pred_abc)\n",
    "abc_f1 = f1_score(y_valid,y_valid_pred_abc)\n",
    "abc_auroc = roc_auc_score(y_valid,y_valid_pred_abc)\n",
    "print('The accuracy of the ADABoost model is:',abc_ac)\n",
    "print('The F1-score of the ADABoost model is:',abc_f1)\n",
    "print('The AUROC of the ADABoost model is:',abc_auroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51bc037",
   "metadata": {},
   "source": [
    "#### Comparing the performance of the various models used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4abea459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Decision Tree</th>\n",
       "      <th>Pruned Decision Tree</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-1 score</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Standard Decision Tree Pruned Decision Tree Bagging Classifier  \\\n",
       "Accuracy                     NaN                  NaN                NaN   \n",
       "F-1 score                    NaN                  NaN                NaN   \n",
       "AUROC                        NaN                  NaN                NaN   \n",
       "\n",
       "          Random Forest AdaBoost  \n",
       "Accuracy            NaN      NaN  \n",
       "F-1 score           NaN      NaN  \n",
       "AUROC               NaN      NaN  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.DataFrame(columns=['Standard Decision Tree','Pruned Decision Tree','Bagging Classifier','Random Forest','AdaBoost'], index = ['Accuracy','F-1 score','AUROC'])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c28797cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61538462, 0.71615721, 0.5599575 ],\n",
       "       [0.65088757, 0.78228782, 0.52352763],\n",
       "       [0.61538462, 0.68292683, 0.6027626 ],\n",
       "       [0.64497041, 0.71698113, 0.62234366],\n",
       "       [0.66272189, 0.77108434, 0.57559199]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_list = np.array([[fg_ac,fg_f1,fg_auroc],[pr_ac,pr_f1,pr_auroc],[bcf_ac,bcf_f1,bcf_auroc],[rf_ac,rf_f1,rf_auroc],[abc_ac,abc_f1,abc_auroc]])\n",
    "performance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1b6ff666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Decision Tree</th>\n",
       "      <th>Pruned Decision Tree</th>\n",
       "      <th>Bagging Classifier</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.650888</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.644970</td>\n",
       "      <td>0.662722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-1 score</th>\n",
       "      <td>0.716157</td>\n",
       "      <td>0.782288</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.559957</td>\n",
       "      <td>0.523528</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.622344</td>\n",
       "      <td>0.575592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Standard Decision Tree  Pruned Decision Tree  Bagging Classifier  \\\n",
       "Accuracy                 0.615385              0.650888            0.615385   \n",
       "F-1 score                0.716157              0.782288            0.682927   \n",
       "AUROC                    0.559957              0.523528            0.602763   \n",
       "\n",
       "           Random Forest  AdaBoost  \n",
       "Accuracy        0.644970  0.662722  \n",
       "F-1 score       0.716981  0.771084  \n",
       "AUROC           0.622344  0.575592  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,j in zip(list(performance.columns),np.arange(0,5)):\n",
    "    performance[i] = performance_list[j]\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b0c5d",
   "metadata": {},
   "source": [
    "#### INFERENCE : \n",
    "Based on F-1 score, **the pruned decision tree machine learning model using TF-IDF(term-frequency inverse \n",
    "document frequency)** has outperformed all the machine learning models that used word2vec technique.\n",
    "\n",
    "Based on AUROC score, **the bagging classifier machine learning model using word2vec** has outperformed all the machine learning models that used TFIDF technique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
